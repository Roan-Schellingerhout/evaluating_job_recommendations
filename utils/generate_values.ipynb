{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2242453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c89aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_side = {\"hasSubType\", \"hasDegree\", \"inCurrentIndustry\", \"wantsIndustry\", \"inCurrentType\",\n",
    "                  \"hasSkill\", \"wantsType\", \"interactedWith\"}\n",
    "\n",
    "company_side = {\"interactedBy\", \"isHeldBy\", \"isWantedTypeOf\", \"isSubTypeOf\", \"isRequiredDegreeOf\", \n",
    "                \"isMaxDegreeOf\", \"isUserDegreeOf\", \"isCurrentIndustryOf\", \"isWantedIndustryOf\", \"isCurrentTypeOf\"}\n",
    "\n",
    "\n",
    "converter = {\"hasSubType\" : \"valt onder\",\n",
    "             \"isSubTypeOf\" : \"is overkoepelend over\",\n",
    "             \"requiresDegree\" : \"vereist diploma\",\n",
    "             \"maxDegree\" : \"maximaal diploma\",\n",
    "             \"hasDegree\" : \"heeft diploma\",\n",
    "             \"inCurrentIndustry\" : \"werkt binnen industrie\", \n",
    "             \"wantsIndustry\" : \"wil werken in industrie\",\n",
    "             \"inCurrentType\" : \"werkt binnen type\", \n",
    "             \"hasSkill\" : \"heeft vaardigheid\", \n",
    "             \"wantsType\" : \"wil type\",\n",
    "             \"isRequiredDegreeOf\" : \"is vereist diploma van\", \n",
    "             \"isMaxDegreeOf\" : \"is maximaal diploma van\",\n",
    "             \"isUserDegreeOf\" : \"heeft diploma\",\n",
    "             \"isCurrentIndustryOf\" : \"is huidige industrie van\",\n",
    "             \"isWantedIndustryOf\" : \"is gewilde industrie van\",\n",
    "             \"isCurrentTypeOf\" : \"is huidig type van\",\n",
    "             \"isWantedTypeOf\" : \"is gewild type van\",\n",
    "             \"isHeldBy\" : \"vaardigheid in bezit van\",\n",
    "             \"interactedWith\" : \"heeft vervuld\",\n",
    "             \"interactedBy\" : \"is vervuld door\"}\n",
    "\n",
    "converter = {v: k for k, v in converter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e5726ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006519317626953125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 13,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa137a36857043b29f50deb98fc65f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006359100341796875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 13,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401e5b5ab63c4290a26e017109b4b537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for diri in [\"candidate\", \"company\"]:\n",
    "    new_data = defaultdict(lambda : defaultdict(lambda : defaultdict(lambda : defaultdict(lambda : defaultdict(list)))))\n",
    "\n",
    "    with open(f\"./data/{diri}_explanations.json\") as f:\n",
    "        exp = json.load(f)\n",
    "\n",
    "        # Loop over all candidates\n",
    "        for candidate in tqdm(exp):\n",
    "            with open(f\"./data/hits/{candidate}.json\") as f2:\n",
    "                hits = json.load(f2)\n",
    "\n",
    "            with open(f\"./data/misses/{candidate}.json\") as f3:\n",
    "                misses = json.load(f3)\n",
    "\n",
    "            # Find metadata\n",
    "            hits_and_misses = {user : \n",
    "                                   {job: values for job, values in {**hits, **misses}[user].items()}\n",
    "                               for user in {**hits, **misses}.keys()}\n",
    "\n",
    "            # update all jobs\n",
    "            for job in exp[candidate]:\n",
    "                all_links = hits_and_misses[job][\"links\"]\n",
    "\n",
    "                for direction in [\"candidate\", \"company\"]:\n",
    "                    full_explanation = exp[candidate][job][\"explanation\"][direction]   \n",
    "                    G = nx.DiGraph([[i[0], i[1]] for i in full_explanation])\n",
    "                                        \n",
    "                    if direction == \"candidate\":\n",
    "                        keep = list(nx.all_simple_paths(G, candidate, job))\n",
    "                    else:\n",
    "                        keep = list(nx.all_simple_paths(G, job, candidate))\n",
    "                                        \n",
    "                    keep = [list(path) for path in map(nx.utils.pairwise, keep)]\n",
    "                    keep = set([item for sublist in keep for item in sublist])\n",
    "                    \n",
    "                    filtered_explanation = sorted([[i[0], i[1], i[2]] for i in full_explanation if (i[0], i[1]) in keep\n",
    "                                                   and ((i[0], i[1]) != (candidate, job)) \n",
    "                                                   and ((i[1], i[0]) != (candidate, job))])\n",
    "                    \n",
    "\n",
    "\n",
    "                    sums = {}\n",
    "\n",
    "\n",
    "                    for k, g in groupby(filtered_explanation, lambda x: x[0]):\n",
    "                        sums[k] = sum([float(i[2]) for i in g])\n",
    "\n",
    "                    # Only look at edges for the current direction, and fix their values so that they add to 1\n",
    "                    filtered_explanations = [[i[0], i[1], str(float(i[2]) / sums[i[0]])] if sums[i[0]] else \n",
    "                                             [i[0], i[1], 1] for i in filtered_explanation]\n",
    "                    \n",
    "#                     if candidate == \"u4186\" and job == \"j127874\":\n",
    "#                         print(filtered_explanation)\n",
    "#                         print(filtered_explanations)\n",
    "#                         print(\"\\n\\n\")\n",
    "\n",
    "                    new_data[candidate][job][\"explanation\"][direction][\"real\"] = filtered_explanations\n",
    "                    new_data[candidate][job][\"explanation\"][\"gen_pred\"] = exp[candidate][job][\"explanation\"][\"gen_pred\"]\n",
    "                    new_data[candidate][job][\"explanation\"][\"can_pred\"] = exp[candidate][job][\"explanation\"][\"can_pred\"]\n",
    "                    new_data[candidate][job][\"explanation\"][\"com_pred\"] = exp[candidate][job][\"explanation\"][\"com_pred\"]\n",
    "                    new_data[candidate][job][\"explanation\"][\"ground_truth\"] = exp[candidate][job][\"explanation\"][\"ground_truth\"]\n",
    "\n",
    "                    # Make random weights\n",
    "                    total = {}\n",
    "                    for k, g in groupby(filtered_explanations, lambda x: x[0]):  \n",
    "                        total[k] = len(list(g))\n",
    "\n",
    "                    random_values = {k: list(np.random.random(size=v)) for k, v in total.items()}\n",
    "                    # random_weights = {k: list(v/sum(v)) for k, v in random_values.items()}  \n",
    "                                                           \n",
    "                    random_explanations = [[i[0], i[1], str(random_values[i[0]].pop())] for i in filtered_explanations]\n",
    "                    \n",
    "                    new_data[candidate][job][\"explanation\"][direction][\"random\"] = random_explanations\n",
    "                    \n",
    "    with open(f\"./data/{diri}_explanations_updated.json\", \"w+\") as f_new:\n",
    "        json.dump(new_data, f_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbe759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
